{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datascience import *\n",
    "import numpy as np\n",
    "from math import *\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lesson 28: Method of Moments Estimation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will continue this block with a brief look into estimators and their properties. Suppose we are presented with a random sample of observations and we are interested in the true underlying process from which these observations originated. If we know, or assume, the underlying distribution of these data, we can use the sample to estimate the parameters of that distribution. \n",
    "\n",
    "## Single Parameter \n",
    "\n",
    "Specifically, let $x_1,x_2,...,x_n$ be an iid (independent, identically distributed) sample from a distribution with a single parameter $\\theta$. Typically, the expected value (or average) of a random variable with this distribution can be expressed as a function of $\\theta$. We also know that the sample mean, $\\bar{X}$ is our best guess at true mean, given our data. So we simply set $E(X)$ equal to our sample mean and solve for $\\theta$. The result is the method of moments estimate of $\\theta$, and we write it as $\\hat{\\theta}_{MoM}$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 1: Exponential Distribution\n",
    "\n",
    "Suppose $x_1,x_2,...,x_n$ is a random sample of size $n$ from the exponential distribution with unknown parameter $\\lambda$. I would like to obtain $\\hat{\\lambda}_{MoM}$, the method of moments estimate of $\\lambda$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From last block, I know that if $X\\sim \\textsf{Exp}(\\lambda)$, then $E(X)=\\frac{1}{\\lambda}$. In other words, our true, population average is $1 \\over \\lambda$. Our best guess of our average given our data is simply the sample mean $\\bar{X}$. So, ideally, $1 \\over \\lambda$ should be close to $\\bar{X}$. We set these two equal to each other and solve for $\\lambda$:\n",
    "\n",
    "$$\n",
    "{1 \\over \\lambda} = \\bar{X}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\hat{\\lambda}_{MoM} = {1 \\over \\bar{X}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 2: Uniform Distribution\n",
    "\n",
    "Suppose $x_1,x_2,...,x_n$ is a random sample of size $n$ from the uniform distribution on the domain $0\\leq X \\leq b$. In other words, $X\\sim \\textsf{Unif}(0,b)$. Find $\\hat{b}_{MoM}$, the method of moments estimate of b. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{align}\n",
    "E(X)&=\\frac{0+b}{2}\\\\\n",
    "\\bar{X}&=\\frac{\\hat{b}_{MoM}}{2}\\\\\n",
    "2\\bar{X}&=\\hat{b}_{MoM}\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose I obtain the following values in my sample: $(0.2,0.4,0.3,0.9,0.4)$. What is our estimate of $b$? What is wrong with that estimate? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8800000000000001"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2*np.mean([0.2, 0.4, 0.3, 0.9, 0.4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*We estimate $b$ to be 0.88, but since $x$ can equal 0.9, $b$ must be at least 0.9.*\n",
    "\n",
    "*MoM is unreliable when the domain of the variable depends upon the parameter in question.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiple Parameters\n",
    "\n",
    "We can extend this to more than one parameter. Suppose our sample comes from a distribution with multiple parameters. We would simply use the higher moments and solve the resulting system of equations. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 3: Normal Distribution\n",
    "\n",
    "Suppose $x_1,x_2,...,x_n$ is a random sample of size $n$ from the normal distribution with unknown parameters $\\mu$ and $\\sigma$. I would like to obtain $\\hat{\\mu}_{MoM}$ and $\\hat{\\sigma}_{MoM}$. \n",
    "\n",
    "This is fairly straight forward, since $\\mu$ and $\\sigma$ are directly interpreted as the mean and standard deviation. Specifically, if $X\\sim \\textsf{Norm}(\\mu,\\sigma)$, then $E(X)=\\mu$. Thus, $\\hat{\\mu}_{MoM} = \\bar{X}$. Further, $Var(X)=\\sigma^2$, so we can set this equal to the second sample moment around the mean: \n",
    "$$\n",
    "Var(X)=\\sigma^2 \\approx {\\sum (X_i-\\bar{X})^2 \\over n}\n",
    "$$\n",
    "\n",
    "So,\n",
    "$$\n",
    "\\hat{\\sigma}_{MoM} = \\sqrt{{\\sum (X_i-\\bar{X})^2 \\over n}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 4: Gamma Distribution\n",
    "\n",
    "Suppose $x_1,x_2,...,x_n$ is a random sample of size $n$ from the Gamma distribution with unknown parameters $\\alpha$ and $\\lambda$. Find $\\hat{\\alpha}_{MoM}$ and $\\hat{\\lambda}_{MoM}$. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall that if $X\\sim \\textsf{Gamma}(\\alpha,\\lambda)$, $E(X)={\\alpha \\over \\lambda}$ and $Var(X)={\\alpha \\over \\lambda^2}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{align}\n",
    "E(X) &= \\frac{\\alpha}{\\lambda} &Var(X)&=\\frac{\\alpha}{\\lambda^2}\\\\\n",
    "\\bar{X} &= \\frac{\\hat{\\alpha}_{MoM}}{\\hat{\\lambda}_{MoM}} \n",
    "    &E((X-\\bar{X})^2)&=\\frac{1}{\\hat{\\lambda}_{MoM}}\\frac{\\hat{\\alpha}_{MoM}}{\\hat{\\lambda}_{MoM}}\\\\\n",
    "&&{\\sum (X_i-\\bar{X})^2 \\over n}&=\\frac{1}{\\hat{\\lambda}_{MoM}}\\bar{X}\\\\\n",
    "&&\\hat{\\lambda}_{MoM}&=\\frac{\\bar{X}n}{\\sum (X_i-\\bar{X})^2}\\\\\n",
    "\\bar{X} &= \\alpha\\frac{\\sum (X_i-\\bar{X})^2}{\\bar{X}n}\\\\\n",
    "\\frac{\\bar{X}^2 n}{\\sum (X_i-\\bar{X})^2}&=\\alpha\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bias\n",
    "\n",
    "Note that our method of moment estimates are themselves random variables (since they are based on random samples). Thus, each time I obtain a new sample, I will get a new method of moments estimate of my paramter. Over time the average of those estimates should be close to the true value of the paramter. In other words, $E(\\hat{\\theta}_{MoM})$ should equal $\\theta$. If not, the estimate is said to be biased. \n",
    "\n",
    "### Example 5\n",
    "Going back to the normal example, find $E(\\hat{\\mu}_{MoM})$ and $E(\\hat{\\sigma}^2_{MoM})$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, recall that if $X\\sim \\textsf{Norm}(\\mu,\\sigma)$, then \n",
    "\n",
    "1. $E(X)=\\mu$ \n",
    "\n",
    "2. $Var(X)=E(X^2)-E(X)^2 = \\sigma^2$, so $E(X^2)=\\sigma^2 + \\mu^2$\n",
    "\n",
    "3. $\\bar{X} \\sim \\textsf{Norm}(\\mu,{\\sigma^2 \\over n})$\n",
    "\n",
    "    a. $E(\\bar{X})=\\mu$\n",
    "\n",
    "    b. $E(\\bar{X}^2)={\\sigma^2 \\over n} + \\mu^2$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{align}\n",
    "E(\\hat{\\mu}_{MoM})&=E(\\bar{X}) &E(\\hat{\\sigma}^2_{MoM})&=E\\left(\\sqrt{\\sum (X_i-\\bar{X})^2 \\over n}^2\\right)\\\\\n",
    "&=\\mu &&=\\frac{1}{n}E\\left(\\sum (X_i-\\bar{X})^2\\right)\\\\\n",
    "&&&=\\frac{1}{n}E\\left(\\sum (X_i^2 - 2 X_i \\bar{X} + \\bar{X}^2) \\right)\\\\\n",
    "&&&=\\frac{1}{n}E\\left( \\sum X_i^2 - 2\\bar{X}\\sum X_i + n\\bar{X}^2 \\right)\\\\\n",
    "&&&=\\frac{1}{n}E\\left(\\sum X_i^2 - 2\\bar{X}(n\\bar{X}) + n\\bar{X}^2 \\right)\\\\\n",
    "&&&=\\frac{1}{n}E\\left(\\sum X_i^2 - n\\bar{X}^2 \\right)\\\\\n",
    "&&&=\\frac{1}{n} \\left(\\sum E(X_i^2) - n\\bar{X}^2 \\right)\\\\\n",
    "&&&=\\frac{1}{n} (nE(X^2) - n\\bar{X}^2)\\\\\n",
    "&&&=E(X^2) - \\bar{X}^2\\\\\n",
    "&&&=E(X^2) - E(\\bar{X})^2\\\\\n",
    "&&&=(\\sigma^2 + \\mu^2) - \\left({\\sigma^2 \\over n} + \\mu^2\\right)\\\\\n",
    "&&&=\\left(\\sigma^2 - {\\sigma^2 \\over n}\\right) + (\\mu^2 - \\mu^2)\\\\\n",
    "&&&=\\sigma^2 \\left(1-\\frac{1}{n}\\right)\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Class notes: $\\hat{\\mu}_{MoM}$ is a random variable, not a constant. If it's good, its average value should be the value it is trying to estimate.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
